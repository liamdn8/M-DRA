"""
Simple M-DRA Solver CLI

Unified interface for running M-DRA optimization solvers.
"""

import os
import sys
import argparse
from pathlib import Path


def run_solver(dataset_path: str, mode: str = 'x', output_dir: str = 'results', margin: float = 0.7):
    """Run a specific solver on a dataset."""
    dataset_path = Path(dataset_path)
    output_dir = Path(output_dir)
    
    if not dataset_path.exists():
        print(f"‚ùå Error: Dataset path does not exist: {dataset_path}")
        return False
    
    # Check for required files
    required_files = ['clusters.csv', 'nodes.csv', 'jobs.csv']
    missing_files = [f for f in required_files if not (dataset_path / f).exists()]
    if missing_files:
        print(f"‚ùå Error: Missing dataset files: {missing_files}")
        return False
    
    # Create hierarchical output directory: results/dataset/solver/margin
    dataset_name = dataset_path.name
    margin_str = f"{margin:.1f}".replace('.', '_')  # Convert to string (e.g., 0.8 -> 0_8)
    solver_output = output_dir / dataset_name / f"solver_{mode}" / margin_str
    solver_output.mkdir(parents=True, exist_ok=True)
    
    print(f"üöÄ Running solver_{mode}...")
    print(f"   Dataset: {dataset_path}")
    print(f"   Output: {solver_output}")
    print(f"   Margin: {margin}")
    print(f"   Files: PNG, CSV, MD")
    
    # Import and run the appropriate solver
    try:
        if mode == 'x':
            from mdra_solver import solver_x
            solver_main = solver_x.main
        elif mode == 'y':
            from mdra_solver import solver_y
            solver_main = solver_y.main
        elif mode == 'xy':
            from mdra_solver import solver_xy  
            solver_main = solver_xy.main
        else:
            print(f"‚ùå Error: Unknown solver mode: {mode}")
            return False
        
        # Save original argv and set up new arguments
        original_argv = sys.argv.copy()
        
        sys.argv = [
            f"solver_{mode}",
            "--input", str(dataset_path),
            "--out", str(solver_output),
            "--margin", str(margin)
        ]
        
        # Run the solver
        solver_main()
        
        # Restore original argv
        sys.argv = original_argv
        
        # Generate individual run summary
        _generate_run_summary(dataset_path, mode, margin, solver_output)
        
        print(f"‚úÖ solver_{mode} completed successfully")
        print(f"üìÅ Results saved in: {solver_output}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå solver_{mode} failed: {e}")
        return False
    finally:
        # Always restore original argv
        sys.argv = original_argv


def _generate_run_summary(dataset_path, mode, margin, output_dir):
    """Generate a markdown summary for an individual solver run."""
    from datetime import datetime
    
    dataset_name = dataset_path.name
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    margin_str = f"{margin:.1f}".replace('.', '_')
    
    # Try to read the solution files to get results
    sol_file = output_dir / f"m{margin:.1f}_sol_clusters_load.csv"
    plot_file = output_dir / f"m{margin:.1f}_plot_sol_clusters_load.png"
    
    relocation_cost = "Unknown"
    status = "Unknown"
    
    # Look for any output files to extract status and cost
    for file in output_dir.glob("*.out"):
        try:
            with open(file, 'r') as f:
                content = f.read()
                if "Solver status: optimal" in content:
                    status = "Optimal"
                elif "Solver status: infeasible" in content:
                    status = "Infeasible"
                elif "Solver status:" in content:
                    status_line = [line for line in content.split('\n') if 'Solver status:' in line]
                    if status_line:
                        status = status_line[0].split(':')[1].strip()
        except:
            pass
    
    summary_content = f"""# Solver Run Summary

## Configuration
- **Dataset:** {dataset_name}
- **Solver Mode:** solver_{mode}
- **Margin:** {margin:.2f} ({margin*100:.0f}%)
- **Timestamp:** {timestamp}
- **Output Directory:** {output_dir}

## Results
- **Status:** {status}
- **Relocation Cost:** {relocation_cost}

## Files Generated
- `m{margin:.1f}_sol_clusters_load.csv` - Cluster resource usage over time
- `m{margin:.1f}_plot_sol_clusters_load.png` - Visualization of cluster loads
- `*.out` - Solver output files

## File Structure
```
{output_dir}/
‚îú‚îÄ‚îÄ m{margin:.1f}_*.csv     # Solution data files
‚îú‚îÄ‚îÄ m{margin:.1f}_*.png     # Visualization plots
‚îî‚îÄ‚îÄ *.out                   # Solver output logs
```

---
*Generated by M-DRA Simple Solver CLI*
"""
    
    # Save summary in the output directory
    summary_file = output_dir / f"run_summary_{mode}_m{margin:.1f}.md"
    with open(summary_file, 'w') as f:
        f.write(summary_content)


def generate_dataset_summary(dataset_path, output_dir='results'):
    """Generate a comprehensive summary for all solvers on a dataset with margin analysis."""
    from datetime import datetime
    import glob
    import re
    
    dataset_path = Path(dataset_path)
    dataset_name = dataset_path.name
    output_dir = Path(output_dir)
    dataset_results_dir = output_dir / dataset_name
    
    if not dataset_results_dir.exists():
        print(f"‚ùå No results found for dataset {dataset_name}")
        return
    
    # Collect all results across solvers and margins
    results = {}
    min_margins = {}
    
    for solver_dir in dataset_results_dir.glob("solver_*"):
        solver_name = solver_dir.name
        solver_mode = solver_name.split('_')[1]  # Extract x, y, or xy
        results[solver_mode] = {}
        
        # Find all margin directories
        for margin_dir in solver_dir.glob("*"):
            if margin_dir.is_dir():
                margin_str = margin_dir.name
                margin = float(margin_str.replace('_', '.'))
                
                # Look for result files to extract optimal cost
                optimal_cost = "N/A"
                status = "Unknown"
                
                # Try to find results from CSV or markdown files
                csv_files = list(margin_dir.glob("*.csv"))
                md_files = list(margin_dir.glob("*run_summary*.md"))
                
                if md_files:
                    try:
                        with open(md_files[0], 'r') as f:
                            content = f.read()
                            # Extract cost from solver output if available
                            cost_match = re.search(r'Optimal relocations.*?=\s*([\d.]+)', content)
                            if cost_match:
                                optimal_cost = float(cost_match.group(1))
                                status = "Optimal"
                            elif "infeasible" in content.lower():
                                status = "Infeasible"
                    except:
                        pass
                
                results[solver_mode][margin] = {
                    'cost': optimal_cost,
                    'status': status
                }
        
        # Find minimum feasible margin
        feasible_margins = [m for m, r in results[solver_mode].items() 
                           if r['status'] == 'Optimal']
        min_margins[solver_mode] = min(feasible_margins) if feasible_margins else "N/A"
    
    # Generate summary report
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    summary_content = f"""# Dataset Summary: {dataset_name}

*Generated on: {timestamp}*

## Dataset Information
- **Name:** {dataset_name}
- **Location:** {dataset_path}
"""

    # Add dataset size info
    try:
        with open(dataset_path / "clusters.csv", 'r') as f:
            clusters = len(f.readlines()) - 1
        with open(dataset_path / "nodes.csv", 'r') as f:
            nodes = len(f.readlines()) - 1  
        with open(dataset_path / "jobs.csv", 'r') as f:
            jobs = len(f.readlines()) - 1
        
        summary_content += f"- **Scale:** {clusters} clusters, {nodes} nodes, {jobs} jobs\n"
    except:
        summary_content += "- **Scale:** Unable to read dataset files\n"

    summary_content += """
## Solver Performance Summary

### Minimum Feasible Margins
| Solver | Minimum Margin | Notes |
|--------|----------------|-------|
"""
    
    for solver_mode in ['x', 'y', 'xy']:
        min_margin = min_margins.get(solver_mode, 'N/A')
        notes = ""
        if solver_mode == 'xy':
            notes = "üèÜ **Best overall performance**"
        elif solver_mode == 'x':
            notes = "Job-only optimization"
        elif solver_mode == 'y':
            notes = "Node-only optimization"
        
        summary_content += f"| solver_{solver_mode} | {min_margin} | {notes} |\n"
    
    summary_content += """
### Cost Analysis by Margin

| Margin | solver_x | solver_y | solver_xy | Best Choice |
|--------|----------|----------|-----------|-------------|
"""
    
    # Get all margins tested across all solvers
    all_margins = set()
    for solver_results in results.values():
        all_margins.update(solver_results.keys())
    
    for margin in sorted(all_margins):
        x_cost = results.get('x', {}).get(margin, {}).get('cost', 'N/A')
        y_cost = results.get('y', {}).get(margin, {}).get('cost', 'N/A')
        xy_cost = results.get('xy', {}).get(margin, {}).get('cost', 'N/A')
        
        # Determine best choice
        costs = []
        if isinstance(x_cost, (int, float)):
            costs.append(('solver_x', x_cost))
        if isinstance(y_cost, (int, float)):
            costs.append(('solver_y', y_cost))
        if isinstance(xy_cost, (int, float)):
            costs.append(('solver_xy', xy_cost))
        
        if costs:
            best_solver, best_cost = min(costs, key=lambda x: x[1])
            best_choice = f"**{best_solver}** ({best_cost})"
        else:
            best_choice = "No feasible solution"
        
        summary_content += f"| {margin:.1f} | {x_cost} | {y_cost} | {xy_cost} | {best_choice} |\n"
    
    summary_content += """
## Key Insights

### Performance Ranking
1. **solver_xy (Joint Optimization)**: Typically achieves the lowest cost by optimizing both jobs and nodes simultaneously
2. **solver_y (Node Optimization)**: Second-best performance, optimizes node placement with fixed job assignments  
3. **solver_x (Job Optimization)**: Baseline performance, optimizes job assignment with fixed node placement

### Recommendations
- **For new deployments**: Use solver_xy with appropriate margin for optimal resource allocation
- **For job rebalancing**: Use solver_x when node infrastructure cannot be changed
- **For node optimization**: Use solver_y when job placements are fixed

---
*Generated by M-DRA Simple Solver CLI*
"""
    
    # Save dataset summary
    summary_file = output_dir / f"summary_{dataset_name}.md"
    with open(summary_file, 'w') as f:
        f.write(summary_content)
    
    print(f"üìä Dataset summary generated: {summary_file}")
    return summary_file


def main():
    """Main CLI interface."""
    parser = argparse.ArgumentParser(
        description='M-DRA Solver - Run optimization on datasets',
        epilog='''
Examples:
  # Run job allocation solver
  python simple_solver_cli.py data/demo --mode x
  
  # Run all solvers
  python simple_solver_cli.py data/demo --mode all
  
  # Custom output and margin
  python simple_solver_cli.py data/demo --output my_results --margin 0.8
        '''
    )
    
    parser.add_argument('dataset_path', help='Path to dataset directory')
    parser.add_argument('--mode', choices=['x', 'y', 'xy', 'all'], default='x',
                       help='Solver mode: x (jobs), y (nodes), xy (joint), all (default: x)')
    parser.add_argument('--output', '-o', default='results',
                       help='Output directory (default: results)')
    parser.add_argument('--margin', '-m', type=float, default=0.7,
                       help='Resource utilization margin (default: 0.7)')
    
    args = parser.parse_args()
    
    print("üîß M-DRA Solver")
    print("=" * 50)
    
    success = True
    
    if args.mode == 'all':
        modes = ['x', 'y', 'xy']
    else:
        modes = [args.mode]
    
    for mode in modes:
        if not run_solver(args.dataset_path, mode, args.output, args.margin):
            success = False
        print()  # Add spacing between solvers
    
    print("=" * 50)
    if success:
        print("üéâ All requested solvers completed successfully!")
        print(f"üìÇ Results in: {args.output}/")
        
        # Generate dataset summary if all solvers were run
        if args.mode == 'all':
            print()
            print("üìä Generating dataset summary...")
            generate_dataset_summary(args.dataset_path, args.output)
            for mode in modes:
                print(f"   {args.output}/{Path(args.dataset_path).name}/solver_{mode}/")
        else:
            print(f"   {args.output}/{Path(args.dataset_path).name}/solver_{args.mode}/")
    else:
        print("‚ùå Some solvers failed. Check output above for details.")
        return 1
    
    return 0


if __name__ == '__main__':
    sys.exit(main())